{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09fcf997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from wordcloud import wordcloud \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabfd7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>subject hpl nom januari 9 2001 see attach file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonder ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>subject photoshop window offic cheap main tren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1      0  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2      0  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3      1  Subject: photoshop , windows , office . cheap ...   \n",
       "4      0  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  subject enron methanol meter 988291 follow not...  \n",
       "1  subject hpl nom januari 9 2001 see attach file...  \n",
       "2  subject neon retreat ho ho ho around wonder ti...  \n",
       "3  subject photoshop window offic cheap main tren...  \n",
       "4  subject indian spring deal book teco pvr reven...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c149caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>subject hpl nom januari 9 2001 see attach file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonder ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>subject photoshop window offic cheap main tren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1      0  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2      0  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3      1  Subject: photoshop , windows , office . cheap ...   \n",
       "4      0  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  subject enron methanol meter 988291 follow not...  \n",
       "1  subject hpl nom januari 9 2001 see attach file...  \n",
       "2  subject neon retreat ho ho ho around wonder ti...  \n",
       "3  subject photoshop window offic cheap main tren...  \n",
       "4  subject indian spring deal book teco pvr reven...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb1f9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "import string \n",
    "\n",
    "ps=PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157c2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranform_text(text):\n",
    "    text=text.lower()\n",
    "    text=nltk.word_tokenize(text)\n",
    "\n",
    "    y=[]\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "\n",
    "    text=y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "\n",
    "    text=y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50932c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampl text punctuat stopword'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranform_text(\"This is a sample text, with some punctuation and stopwords!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd596e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>subject enron methanol meter 988291 follow not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>subject hpl nom januari 9 2001 see attach file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>subject neon retreat ho ho ho around wonder ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>subject photoshop window offic cheap main tren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1      0  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2      0  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3      1  Subject: photoshop , windows , office . cheap ...   \n",
       "4      0  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  subject enron methanol meter 988291 follow not...  \n",
       "1  subject hpl nom januari 9 2001 see attach file...  \n",
       "2  subject neon retreat ho ho ho around wonder ti...  \n",
       "3  subject photoshop window offic cheap main tren...  \n",
       "4  subject indian spring deal book teco pvr reven...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_text'] = df['text'].apply(tranform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9546a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer \n",
    "tfidf=TfidfVectorizer(max_features=500,stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a7b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "y=df['label'].values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83bcc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9868dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a015a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel='sigmoid',C=1,gamma=1.0)\n",
    "knc=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "lr=LogisticRegression(C=1,solver='liblinear')   \n",
    "mnb=MultinomialNB(alpha=1.0)\n",
    "dtc=DecisionTreeClassifier(criterion='gini',max_depth=5)\n",
    "rfc=RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=5)\n",
    "gbc=GradientBoostingClassifier(n_estimators=100,learning_rate=0.1,max_depth=3)\n",
    "xgbc=XGBClassifier(n_estimators=100,learning_rate=0.1,max_depth=3)\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ab8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs= {\n",
    "    'SVC': svc,\n",
    "    'KNeighborsClassifier': knc,\n",
    "    'LogisticRegression': lr,\n",
    "    'MultinomialNB': mnb,\n",
    "    'DecisionTreeClassifier': dtc,\n",
    "    'RandomForestClassifier': rfc,\n",
    "    'GradientBoostingClassifier': gbc,\n",
    "    'XGBClassifier': xgbc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cd67b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,x_train,y_train,x_test,y_test):\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    \n",
    "    print(\"Classifier:\",clf.__class__.__name__)\n",
    "    print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "    print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "    print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89d358a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: SVC\n",
      "Accuracy: 0.93\n",
      "Confusion Matrix:\n",
      " [[69  6]\n",
      " [ 1 24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95        75\n",
      "           1       0.80      0.96      0.87        25\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.89      0.94      0.91       100\n",
      "weighted avg       0.94      0.93      0.93       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy: 0.92\n",
      "Confusion Matrix:\n",
      " [[70  5]\n",
      " [ 3 22]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        75\n",
      "           1       0.81      0.88      0.85        25\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.89      0.91      0.90       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Accuracy: 0.94\n",
      "Confusion Matrix:\n",
      " [[70  5]\n",
      " [ 1 24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96        75\n",
      "           1       0.83      0.96      0.89        25\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.91      0.95      0.92       100\n",
      "weighted avg       0.95      0.94      0.94       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      " [[66  9]\n",
      " [ 5 20]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        75\n",
      "           1       0.69      0.80      0.74        25\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.81      0.84      0.82       100\n",
      "weighted avg       0.87      0.86      0.86       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Accuracy: 0.89\n",
      "Confusion Matrix:\n",
      " [[72  3]\n",
      " [ 8 17]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        75\n",
      "           1       0.85      0.68      0.76        25\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.88      0.82      0.84       100\n",
      "weighted avg       0.89      0.89      0.89       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: RandomForestClassifier\n",
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      " [[72  3]\n",
      " [12 13]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        75\n",
      "           1       0.81      0.52      0.63        25\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.83      0.74      0.77       100\n",
      "weighted avg       0.85      0.85      0.84       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy: 0.92\n",
      "Confusion Matrix:\n",
      " [[70  5]\n",
      " [ 3 22]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        75\n",
      "           1       0.81      0.88      0.85        25\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.89      0.91      0.90       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Accuracy: 0.94\n",
      "Confusion Matrix:\n",
      " [[70  5]\n",
      " [ 1 24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96        75\n",
      "           1       0.83      0.96      0.89        25\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.91      0.95      0.92       100\n",
      "weighted avg       0.95      0.94      0.94       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      " [[66  9]\n",
      " [ 5 20]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        75\n",
      "           1       0.69      0.80      0.74        25\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.81      0.84      0.82       100\n",
      "weighted avg       0.87      0.86      0.86       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Accuracy: 0.89\n",
      "Confusion Matrix:\n",
      " [[72  3]\n",
      " [ 8 17]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        75\n",
      "           1       0.85      0.68      0.76        25\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.88      0.82      0.84       100\n",
      "weighted avg       0.89      0.89      0.89       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: RandomForestClassifier\n",
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      " [[72  3]\n",
      " [12 13]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        75\n",
      "           1       0.81      0.52      0.63        25\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.83      0.74      0.77       100\n",
      "weighted avg       0.85      0.85      0.84       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Accuracy: 0.94\n",
      "Confusion Matrix:\n",
      " [[72  3]\n",
      " [ 3 22]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        75\n",
      "           1       0.88      0.88      0.88        25\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: XGBClassifier\n",
      "Accuracy: 0.96\n",
      "Confusion Matrix:\n",
      " [[73  2]\n",
      " [ 2 23]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        75\n",
      "           1       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Accuracy: 0.94\n",
      "Confusion Matrix:\n",
      " [[72  3]\n",
      " [ 3 22]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        75\n",
      "           1       0.88      0.88      0.88        25\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "\n",
      "\n",
      "Classifier: XGBClassifier\n",
      "Accuracy: 0.96\n",
      "Confusion Matrix:\n",
      " [[73  2]\n",
      " [ 2 23]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        75\n",
      "           1       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_classifier(svc,x_train,y_train,x_test,y_test)\n",
    "train_classifier(knc,x_train,y_train,x_test,y_test)\n",
    "train_classifier(lr,x_train,y_train,x_test,y_test)\n",
    "train_classifier(mnb,x_train,y_train,x_test,y_test)\n",
    "train_classifier(dtc,x_train,y_train,x_test,y_test)\n",
    "train_classifier(rfc,x_train,y_train,x_test,y_test)\n",
    "train_classifier(gbc,x_train,y_train,x_test,y_test)\n",
    "train_classifier(xgbc,x_train,y_train,x_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
